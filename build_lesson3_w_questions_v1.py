import argparse
import os
import re

from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml import OxmlElement
from docx.oxml.ns import qn
from docx.shared import Pt, RGBColor, Cm

# ---------- –¶–≤–µ—Ç–∞ –∏ —à—Ä–∏—Ñ—Ç—ã ----------
BLACK = RGBColor(0, 0, 0)
DARK_RED = RGBColor(139, 0, 0)
DARK_GREEN = RGBColor(0, 100, 0)
PURPLE = RGBColor(102, 0, 153)
THAI_FONT_NAME = "Noto Sans Thai"

OUT_NAME = "cha_lesson_3_w_questions_v1.docx"
SRC_NAME = "cha_lesson_3_w-questions_v8.docx"

BLOCK_TITLES = {
    "üéì Lesson 3 ‚Äî W-Questions ‚Äî Vocabulary: Student Graduation",
    "üë©‚Äçüè´ Explanation",
    "‚úçÔ∏è Examples:",
    "üß† Practice",
    "üéì Vocabulary (Student Graduation)",
    "üß∫ Word bank:",
    "üéì Vocabulary Exercises",
    "üßæ Exit check & Homework",
    "üßæ Exit check (5 quick items):",
}


def new_doc():
    doc = Document()
    for s in doc.sections:
        s.page_height = Cm(29.7)
        s.page_width = Cm(21.0)
        s.left_margin = Cm(2.0)
        s.right_margin = Cm(2.0)
        s.top_margin = Cm(2.0)
        s.bottom_margin = Cm(2.0)
        fp = s.footer.paragraphs[0]
        fp.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run1 = fp.add_run("¬© Cha 2025 ¬∑ Page ")
        run1.font.size = Pt(9)
        run1.font.color.rgb = BLACK
        fld = OxmlElement("w:fldSimple")
        fld.set(qn("w:instr"), "PAGE")
        run2 = fp.add_run()
        run2._r.append(fld)
    return doc


def clone_run(dst_p, src_run):
    r = dst_p.add_run(src_run.text)
    try:
        r.font.bold = src_run.font.bold
        r.font.italic = src_run.font.italic
        r.font.underline = src_run.font.underline
        r.font.size = src_run.font.size
        r.font.all_caps = src_run.font.all_caps
        if src_run.font.color and src_run.font.color.rgb:
            r.font.color.rgb = src_run.font.color.rgb
    except Exception:
        pass
    return r


def clone_paragraph(dst_doc: Document, src_p):
    p = dst_doc.add_paragraph()
    p.alignment = src_p.alignment
    for run in src_p.runs:
        clone_run(p, run)
    return p


def line_ru(doc: Document, txt: str, size=11):
    p = doc.add_paragraph()
    r = p.add_run(f"({txt})")
    r.font.italic = True
    r.font.color.rgb = DARK_RED
    r.font.size = Pt(size)


def line_th(doc: Document, txt: str, size=11):
    p = doc.add_paragraph()
    r = p.add_run(f"({txt})")
    r.font.italic = True
    r.font.color.rgb = DARK_GREEN
    r.font.size = Pt(size)
    r.font.name = THAI_FONT_NAME


def collect_highlight_tokens(src_p) -> list:
    tokens = []
    for run in src_p.runs:
        t = run.text or ""
        for m in re.finditer(r"[A-Z][A-Z ]+[A-Z]", t):
            tok = m.group(0).strip()
            if tok not in tokens:
                tokens.append(tok)
        try:
            if run.font and run.font.underline and not any(
                    ch.isupper() for ch in t):
                w = (t or "").strip()
                if 0 < len(w) <= 15 and w not in tokens:
                    tokens.append(w)
        except Exception:
            pass
    tokens.sort(key=len, reverse=True)
    return tokens


def add_ru_mapped_line_with_highlights(doc: Document, src_p, ru_text: str):
    p = doc.add_paragraph()
    r0 = p.add_run("(")
    r0.font.italic = True
    r0.font.color.rgb = DARK_RED
    hi = collect_highlight_tokens(src_p)
    s = ru_text or ""
    i = 0
    while i < len(s):
        hit_pos = None
        hit_tok = None
        for tok in hi:
            j = s.find(tok, i)
            if j != -1 and (hit_pos is None or j < hit_pos):
                hit_pos = j
                hit_tok = tok
        if hit_pos is None:
            r = p.add_run(s[i:])
            r.font.italic = True
            r.font.color.rgb = DARK_RED
            break
        if hit_pos > i:
            r = p.add_run(s[i:hit_pos])
            r.font.italic = True
            r.font.color.rgb = DARK_RED
        r2 = p.add_run(s[hit_pos:hit_pos + len(hit_tok)])
        r2.font.color.rgb = BLACK
        r2.font.bold = True
        r2.font.underline = True
        r2.font.italic = False
        i = hit_pos + len(hit_tok)
    rz = p.add_run(")")
    rz.font.italic = True
    rz.font.color.rgb = DARK_RED


def add_th_mapped_line_with_highlights(doc: Document, src_p, th_text: str):
    p = doc.add_paragraph()
    r0 = p.add_run("(")
    r0.font.italic = True
    r0.font.color.rgb = DARK_GREEN
    hi = collect_highlight_tokens(src_p)
    s = th_text or ""
    i = 0
    while i < len(s):
        hit_pos = None
        hit_tok = None
        for tok in hi:
            j = s.find(tok, i)
            if j != -1 and (hit_pos is None or j < hit_pos):
                hit_pos = j
                hit_tok = tok
        if hit_pos is None:
            r = p.add_run(s[i:])
            r.font.italic = True
            r.font.color.rgb = DARK_GREEN
            r.font.name = THAI_FONT_NAME
            break
        if hit_pos > i:
            r = p.add_run(s[i:hit_pos])
            r.font.italic = True
            r.font.color.rgb = DARK_GREEN
            r.font.name = THAI_FONT_NAME
        r2 = p.add_run(s[hit_pos:hit_pos + len(hit_tok)])
        r2.font.color.rgb = BLACK
        r2.font.bold = True
        r2.font.underline = True
        r2.font.italic = False
        r2.font.name = THAI_FONT_NAME
        i = hit_pos + len(hit_tok)
    rz = p.add_run(")")
    rz.font.italic = True
    rz.font.color.rgb = DARK_GREEN


def norm_exact(s: str) -> str:
    s = (s or "").strip()
    s = s.replace("\u2011", "-")
    s = s.replace("\u2013", "-")
    s = s.replace("\u2014", "-")
    s = s.replace("\u2212", "-")
    s = re.sub(r"^\s*\d+(?:\.\d+)*[\)\.]?\s+", "", s)
    s = re.sub(r"^[\u2022\-\u2013\u2014]\s+", "", s)
    return re.sub(r"\s+", " ", s)


def strip_list_markers(s: str) -> str:
    return re.sub(r"^[\u2022\-\u2013\u2014]\s+", "", (s or "").strip())


def clean_vocab_en_term(s: str) -> str:
    """–û—á–∏—â–∞–µ—Ç EN-—Ç–µ—Ä–º–∏–Ω Word bank: —É–±–∏—Ä–∞–µ—Ç –ª–∏—Ç–µ—Ä–Ω—É—é –Ω—É–º–µ—Ä–∞—Ü–∏—é (a.), —ç–º–æ–¥–∑–∏; –æ—Å—Ç–∞–≤–ª—è–µ—Ç –ª–∞—Ç–∏–Ω–∏—Ü—É/–ø—Ä–æ–±–µ–ª—ã/–¥–µ—Ñ–∏—Å/—Å–∫–æ–±–∫–∏."""
    s = (s or "").strip()
    s = s.replace("\u2011", "-").replace("\u2013", "-").replace("\u2014",
                                                                "-").replace(
        "\u2212", "-")
    s = re.sub(r"^[A-Za-z]\.[\s]+", "", s)
    s = re.sub(r"[^A-Za-z()\-\s]", "", s)
    s = re.sub(r"\s+", " ", s).strip().lower()
    return s


def load_translations_from_source(path: str) -> dict:
    """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª –ø–µ—Ä–µ–≤–æ–¥–∞: EN —Å—Ç—Ä–æ–∫–∞ + (RU) + (TH) –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏. –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç –±–ª–æ–∫ Word bank."""
    if not path or not os.path.exists(path):
        return {}
    with open(path, "r", encoding="utf-8") as f:
        lines = [ln.rstrip("\n") for ln in f]
    tr = {}
    section = None
    # –∑–∞—â–∏—Ç–∞ –æ—Ç –¥—É–±–ª–µ–π: –ø–æ –∏–Ω–¥–µ–∫—Å—É –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
    added_ru_idx = set()
    added_th_idx = set()
    i = 0
    while i < len(lines):
        L = lines[i].strip()
        if not L:
            i += 1
            continue
        low = L.lower()
        if L in BLOCK_TITLES:
            if "vocabulary (student graduation)" in low:
                section = "vocab"
            elif "vocabulary exercises" in low:
                section = "vocab_ex"
            elif "practice" in low:
                section = "practice"
            elif "exit check" in low or "homework" in low:
                section = "exit"
            elif "explanation" in low:
                section = "expl"
            i += 1
            continue
        # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º word bank ‚Äî —Ç–∞–º –ø–µ—Ä–µ–≤–æ–¥ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
        if section == "vocab":
            i += 1
            continue
        if not L.startswith("("):
            # –°–æ–±–∏—Ä–∞–µ–º –¥–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫ –≤ —Å–∫–æ–±–∫–∞—Ö –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —è–∑—ã–∫ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
            ru = th = None
            j = i + 1
            while j < len(lines) and lines[j].strip().startswith("("):
                raw = lines[j].strip()
                val = raw[1:-1] if (
                        raw.startswith("(") and raw.endswith(")")) else raw
                # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Å–∏–º–≤–æ–ª–∞–º (—Ç–∞–π—Å–∫–∏–π / –∫–∏—Ä–∏–ª–ª–∏—Ü–∞)
                if re.search(r"[\u0E00-\u0E7F]", val):  # Thai block
                    th = val  # –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Å—Ç—Ä–µ—á–µ–Ω–Ω–æ–µ TH
                elif re.search(r"[\u0400-\u04FF]", val):  # Cyrillic
                    ru = val  # –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Å—Ç—Ä–µ—á–µ–Ω–Ω–æ–µ RU
                else:
                    # –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å ‚Äî –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ–º
                    pass
                j += 1
            if ru or th:
                base_key = norm_exact(L)
                pair = {"ru": ru, "th": th}
                tr[base_key] = pair
                alt = norm_exact(strip_list_markers(L))
                if alt != base_key:
                    tr[alt] = pair
                i = j
                continue
        i += 1
    return tr


def load_wordbank_from_source(path: str) -> dict:
    """–ü–∞—Ä—Å–∏—Ç –±–ª–æ–∫ Word bank –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict –ø–æ –∫–ª—é—á—É EN-—Ç–µ—Ä–º–∏–Ω–∞ -> {ru, th}."""
    if not path or not os.path.exists(path):
        return {}
    with open(path, "r", encoding="utf-8") as f:
        lines = [ln.rstrip("\n") for ln in f]
    wb = {}
    section = None
    for L in lines:
        S = L.strip()
        if not S:
            continue
        low = S.lower()
        if S in BLOCK_TITLES:
            if "vocabulary (student graduation)" in low:
                section = "vocab"
            else:
                section = None
            continue
        if section != "vocab":
            continue
        # –æ–∂–∏–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç: a. <emoji?> EN ‚Äî RU ‚Äî TH
        if re.match(r"^[A-Za-z]\.", S) and " ‚Äî " in S:
            parts = re.split(r"\s‚Äî\s", S, maxsplit=2)
            if len(parts) >= 2:
                left = parts[0]
                ru = parts[1] if len(parts) >= 2 else None
                th = parts[2] if len(parts) >= 3 else None
                # –∫–ª—é—á–∏
                keys = set()
                keys.add(norm_exact(left))
                keys.add(norm_exact(re.sub(r"^[A-Za-z]\.[\s]+", "", left)))
                cv = clean_vocab_en_term(left)
                if cv:
                    keys.add(cv)
                for k in keys:
                    wb[k] = {"ru": ru, "th": th}
    return wb


def load_answers_from_source(path: str) -> dict:
    if not path or not os.path.exists(path):
        return {}
    with open(path, "r", encoding="utf-8") as f:
        lines = [ln.rstrip("\n") for ln in f]
    i = 0
    ans = {}
    while i < len(lines):
        en = lines[i].strip()
        if not en:
            i += 1
            continue
        if en in BLOCK_TITLES:
            i += 1
            continue
        if i + 2 <= len(lines) - 1 and lines[i + 1].lstrip().startswith(
                "Answer:") and lines[i + 2].lstrip().startswith("‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"):
            key = norm_exact(en)
            a_en = lines[i + 1].strip()
            a_th = lines[i + 2].strip()
            ans.setdefault(key, []).extend([a_en, a_th])
            i += 3
            if i < len(lines) and not lines[i].strip():
                i += 1
            continue
        i += 1
    return ans


def build():
    parser = argparse.ArgumentParser()
    parser.add_argument("--with-ru", dest="with_ru", action="store_true",
                        default=True)
    parser.add_argument("--no-ru", dest="with_ru", action="store_false")
    parser.add_argument("--with-th", dest="with_th", action="store_true",
                        default=True)
    parser.add_argument("--no-th", dest="with_th", action="store_false")
    parser.add_argument("--translations-source", type=str,
                        default="lesson3_translations_source.txt")
    parser.add_argument("--with-answers", dest="with_answers",
                        action="store_true", default=False)
    parser.add_argument("--answers-source", type=str,
                        default="lesson3_answers_source.txt")
    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä–∫–∏
    if not os.path.exists(SRC_NAME):
        raise FileNotFoundError(f"Source DOCX not found: {SRC_NAME}")
    if not args.translations_source or not os.path.exists(
            args.translations_source):
        raise FileNotFoundError(
            f"Translations source not found: {args.translations_source}")

    # –ì—Ä—É–∑–∏–º –º–∞–ø–ø–∏–Ω–≥–∏
    tr_map = load_translations_from_source(args.translations_source)
    wb_map = load_wordbank_from_source(args.translations_source)
    ans_map = {}
    if args.with_answers and args.answers_source and os.path.exists(
            args.answers_source):
        ans_map = load_answers_from_source(args.answers_source)

    # –ë–∞–∑–∞ –∏ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç
    src = Document(SRC_NAME)
    out = new_doc()

    section = None
    total = len(src.paragraphs)
    for idx, p in enumerate(src.paragraphs, 1):
        text = p.text or ""

        t = text.strip().lower()
        if "vocabulary (student graduation)" in t:
            section = "vocab"
        elif "vocabulary exercises" in t:
            section = "vocab_ex"
        elif "practice" in t:
            section = "practice"
        elif "exit check" in t or "homework" in t:
            section = "exit"
        elif "explanation" in t or "examples" in t:
            section = "expl"

        stripped = text.strip()
        if not stripped:
            continue
        if stripped in BLOCK_TITLES:
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –∫–∞–∫ –µ—Å—Ç—å
            clone_paragraph(out, p)
            continue

        # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –∞–±–∑–∞—Ü —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è –ø–µ—Ä–µ–≤–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π –≤ —Å–∫–æ–±–∫–∞—Ö ‚Äî –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–∏—á–µ–≥–æ
        if stripped.startswith("(") and stripped.endswith(")"):
            # –ù–µ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –∏—Å—Ö–æ–¥–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ –±–∞–∑—ã ‚Äî –º—ã –≥–µ–Ω–µ—Ä–∏–º —Å–≤–æ–∏
            continue

        # –ù–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –ø–µ—Ä–µ–Ω–æ—Å–∏–º —Å–∞–º EN-–∞–±–∑–∞—Ü –≤ –≤—ã—Ö–æ–¥
        new_p = clone_paragraph(out, p)

        # Word bank: –¥–æ–ø–∏—Å—ã–≤–∞–µ–º RU/TH –≤ —Ç—É –∂–µ —Å—Ç—Ä–æ–∫—É
        if section == "vocab" and re.match(r"^[A-Za-z]\.[\s]+", stripped):
            # –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–∏ –ø–æ–∏—Å–∫–∞
            left = stripped.split(" ‚Äî ", 1)[0]
            keys = [
                norm_exact(left),
                norm_exact(re.sub(r"^[A-Za-z]\.[\s]+", "", left)),
                clean_vocab_en_term(left),
                clean_vocab_en_term(re.sub(r"^[A-Za-z]\.[\s]+", "", left)),
            ]
            val = None
            for k in keys:
                if not k:
                    continue
                v = wb_map.get(k)
                if v:
                    val = v
                    break
            if val:
                ru = val.get("ru")
                th = val.get("th")
                if args.with_ru and ru:
                    rr_sep = new_p.add_run(" ‚Äî ")
                    rr_sep.font.italic = True
                    rr_sep.font.color.rgb = DARK_RED
                    rr_run = new_p.add_run(ru)
                    rr_run.font.italic = True
                    rr_run.font.color.rgb = DARK_RED
                if args.with_th and th:
                    th_sep = new_p.add_run(" ‚Äî ")
                    th_sep.font.italic = True
                    th_sep.font.color.rgb = DARK_GREEN
                    trun = new_p.add_run(th)
                    trun.font.italic = True
                    trun.font.color.rgb = DARK_GREEN
                    trun.font.name = THAI_FONT_NAME
            continue

        # –ö–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏: –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã
        key = norm_exact(text)

        # –î–ª—è –±–ª–æ–∫–∞ Exit check ‚Äî –æ—Å–æ–±—ã–π —Ñ–æ—Ä–º–∞—Ç: –º–µ—Ç–∫–∏ "‚Äî RU:" / "‚Äî TH:" –≤–º–µ—Å—Ç–æ —Å—Ç—Ä–æ–∫ –≤ —Å–∫–æ–±–∫–∞—Ö
        if section == "exit":
            if args.with_ru and idx not in added_ru_idx:
                ru_txt = tr_map.get(key, {}).get("ru")
                if ru_txt:
                    pr = out.add_paragraph()
                    rr = pr.add_run(f"‚Äî RU: {ru_txt}")
                    # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å—Ç–∏–ª—å (—á—ë—Ä–Ω—ã–π, –±–µ–∑ –∫—É—Ä—Å–∏–≤–∞)
                    added_ru_idx.add(idx)
            if args.with_th and idx not in added_th_idx:
                th_txt = tr_map.get(key, {}).get("th")
                if th_txt:
                    pt = out.add_paragraph()
                    rt = pt.add_run(f"‚Äî TH: {th_txt}")
                    try:
                        rt.font.name = THAI_FONT_NAME
                    except Exception:
                        pass
                    added_th_idx.add(idx)
        else:
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–µ–∫—Ü–∏–∏ ‚Äî –∫–∞–∫ –≤ —É—Ä–æ–∫–µ 4 (—Å—Ç—Ä–æ–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö —Å –∑–µ—Ä–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
            if args.with_ru and idx not in added_ru_idx:
                ru_txt = tr_map.get(key, {}).get("ru")
                if ru_txt:
                    add_ru_mapped_line_with_highlights(out, p, ru_txt)
                    added_ru_idx.add(idx)
            if args.with_th and idx not in added_th_idx:
                th_txt = tr_map.get(key, {}).get("th")
                if th_txt:
                    add_th_mapped_line_with_highlights(out, p, th_txt)
                    added_th_idx.add(idx)

        # –û—Ç–≤–µ—Ç—ã ‚Äî —Å—Ç—Ä–æ–≥–æ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        if args.with_answers and section in ("practice", "vocab_ex", "exit"):
            a = ans_map.get(key)
            if a:
                for line in a:
                    ap = out.add_paragraph()
                    ar = ap.add_run(line)
                    ar.font.color.rgb = PURPLE

    out.save(OUT_NAME)
    print("[lesson3] Saved:", OUT_NAME)


if __name__ == "__main__":
    build()
